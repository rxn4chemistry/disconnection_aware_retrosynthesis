{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from rxn.chemutils.tokenization import tokenize_smiles\n",
    "from rxn.chemutils.miscellaneous import canonicalize_smiles\n",
    "from rxn.chemutils.utils import remove_atom_mapping\n",
    "\n",
    "from dar.tagging import get_tagged_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start from the provided data which contain atom-mapped reaction SMILES. If processing your own dataset we suggest remapping the reaction SMILES with RXNMapper or an atom-mapping tool of your choice. Your dataset should have as a minimum the 'mapped_reactions' header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('complete_disconnection_labelled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split reactions into reactants and products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"reactants\", \"products\"]] = df[\"mapped_reactions\"].str.split(\">>\", expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag products "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tagged_products\"] = df.apply(lambda x: get_tagged_products(x['reactants'], x['products']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove mapping from reactants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reactants\"] = df[\"reactants\"].apply(remove_atom_mapping)\n",
    "df[\"reactants\"] = df[\"reactants\"].apply(canonicalize_smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenise samples for training disconnection aware retrosynthesis model and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reactants\"] = df[\"reactants\"].apply(tokenize_smiles)\n",
    "df[\"tagged_products\"] = df[\"tagged_products\"].apply(tokenize_smiles)\n",
    "\n",
    "#df['reactants'].to_csv('disconnection_labelled.train.precursors_tokens', index=False, header=False)\n",
    "#df['tagged_products'].to_csv('disconnection_labelled.train.products_tokens', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for training model for automatic identification of disconnection sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"products\"] = df[\"products\"].apply(remove_atom_mapping)\n",
    "df[\"products\"] = df[\"products\"].apply(canonicalize_smiles)\n",
    "df[\"products\"] = df[\"products\"].apply(tokenize_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['products'].to_csv('disconnection_labelled.train.products_tokens', index=False, header=False)\n",
    "#df['tagged_products'].to_csv('disconnection_labelled.train.tagged_products_tokens', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8fffb9b41741f41ef95be7e4f9c74dffdbe0f08fc2be86c213456ec0cc01bf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
